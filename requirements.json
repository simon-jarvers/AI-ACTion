{
    "Technical System Fundamentals": {
      "Intended purpose": {
        "content": "Clearly define and document the intended purpose of the AI system, including its specific objectives, target users, and operational context.",
        "ref": ["Article 9.2.a", "Annex IV.1.a"]
      },
      "System architecture": {
        "content": "Provide a detailed description of the AI system's architecture, including its components, their interactions, and the overall structure of the system.",
        "ref": ["Annex IV.1.b", "Annex IV.2.c"]
      },
      "General logic": {
        "content": "Explain the general logic and decision-making processes employed by the AI system, including the main algorithms and model types used.",
        "ref": ["Annex IV.2.b"]
      },
      "Key design choices": {
        "content": "Document and justify the key design choices made during the development of the AI system, including trade-offs and their implications.",
        "ref": ["Annex IV.2.b"]
      },
      "Training, validation, and testing methods": {
        "content": "Describe the methods used for training, validating, and testing the AI system, including data splitting strategies and evaluation metrics.",
        "ref": ["Annex IV.2.d", "Annex IV.2.g"]
      },
      "Measures to ensure robustness": {
        "content": "Implement and document measures to ensure the AI system's robustness, including handling of errors, anomalies, and unexpected situations.",
        "ref": ["Article 15.4", "Article 15.5"]
      },
      "Computational resources": {
        "content": "Specify the computational resources required for the AI system's operation, including hardware specifications and performance requirements.",
        "ref": ["Annex IV.2.c"]
      }
    },
    "Deployment Guidelines": {
      "Provider's identity and contact details": {
        "content": "Clearly state the identity and contact information of the AI system provider for user inquiries and support.",
        "ref": ["Article 13.3.a", "Annex IV.1.a"]
      },
      "Software/firmware versions": {
        "content": "Provide information on the current software and firmware versions of the AI system, including any dependencies.",
        "ref": ["Annex IV.1.c"]
      },
      "Forms of deployment": {
        "content": "Describe the various forms of deployment available for the AI system, such as cloud-based, on-premises, or edge deployment options.",
        "ref": ["Annex IV.1.d"]
      },
      "Required hardware and resources": {
        "content": "Specify the hardware requirements and other resources necessary for the proper functioning of the AI system in its intended deployment environment.",
        "ref": ["Annex IV.1.e", "Article 13.3.e"]
      },
      "Instructions for use": {
        "content": "Provide clear and comprehensive instructions for the proper use of the AI system, including any limitations and potential risks.",
        "ref": ["Article 13.2", "Article 13.3"]
      },
      "Harmonized standards": {
        "content": "List any harmonized standards or common specifications that the AI system complies with, ensuring adherence to regulatory requirements.",
        "ref": ["Annex IV.7"]
      },
      "EU declaration of conformity": {
        "content": "Include the EU declaration of conformity, confirming that the AI system meets all applicable regulatory requirements.",
        "ref": ["Annex IV.8"]
      }
    },
    "Data": {
      "Data collection processes": {
        "content": "Describe the processes used to collect data for training, validation, and testing of the AI system, ensuring transparency and compliance with data protection regulations.",
        "ref": ["Article 10.2.b"]
      },
      "Data preparation operations": {
        "content": "Detail the operations performed on the collected data, including cleaning, preprocessing, and augmentation techniques used to prepare the data for use in the AI system.",
        "ref": ["Article 10.2.c"]
      },
      "Data availability and suitability": {
        "content": "Assess and document the availability and suitability of the data used, considering factors such as relevance, representativeness, and completeness.",
        "ref": ["Article 10.2.e", "Article 10.3"]
      },
      "Data gaps or shortcomings": {
        "content": "Identify and address any gaps or shortcomings in the data used, including potential biases or limitations that could affect the AI system's performance.",
        "ref": ["Article 10.2.h"]
      },
      "Measures to prevent biases": {
        "content": "Implement and document measures to prevent or mitigate biases in the data, ensuring fair and equitable performance of the AI system across different user groups.",
        "ref": ["Article 10.2.f", "Article 10.2.g"]
      },
      "Relevant datasets": {
        "content": "Provide information on the relevant datasets used for training, validation, and testing of the AI system, including their sources and characteristics.",
        "ref": ["Article 10.3", "Article 10.4"]
      },
      "Input data requirements": {
        "content": "Specify the requirements for input data to be used with the AI system, including format, quality, and any necessary preprocessing steps.",
        "ref": ["Article 10.2.a", "Article 13.3.b.vi"]
      }
    },
    "Risk Management": {
      "Identify and analyze risks": {
        "content": "Conduct a comprehensive risk identification and analysis process, considering potential negative impacts of the AI system on various stakeholders and contexts.",
        "ref": ["Article 9.2.a", "Article 9.2.b"]
      },
      "Evaluate risks under various conditions": {
        "content": "Assess the identified risks under different operating conditions and scenarios, including edge cases and potential misuse of the AI system.",
        "ref": ["Article 9.2.b"]
      },
      "Consider impacts on vulnerable groups": {
        "content": "Explicitly consider and evaluate the potential impacts of the AI system on vulnerable groups, ensuring inclusive and fair performance.",
        "ref": ["Article 9.9"]
      },
      "Implement risk mitigation measures": {
        "content": "Design and implement appropriate risk mitigation measures to address identified risks, including technical and organizational controls.",
        "ref": ["Article 9.2.d", "Article 9.5"]
      },
      "Ensure acceptable residual risk": {
        "content": "Evaluate the effectiveness of implemented risk mitigation measures and ensure that any residual risks are within acceptable levels.",
        "ref": ["Article 9.5"]
      },
      "Test AI systems": {
        "content": "Conduct thorough testing of the AI system to verify its performance, safety, and compliance with specified requirements and risk mitigation measures.",
        "ref": ["Article 9.6", "Article 9.8"]
      },
      "Implement cybersecurity measures": {
        "content": "Implement appropriate cybersecurity measures to protect the AI system and its data from unauthorized access, manipulation, or attacks.",
        "ref": ["Article 15.5"]
      }
    },
    "Performance Evaluation": {
      "Implement automatic event logging": {
        "content": "Implement an automatic logging mechanism to record events and behaviors of the AI system during operation, facilitating monitoring and analysis.",
        "ref": ["Article 12.1", "Article 12.2"]
      },
      "Establish post-market monitoring": {
        "content": "Develop and implement a post-market monitoring system to continuously evaluate the AI system's performance and identify potential issues or improvements.",
        "ref": ["Article 72.1", "Article 72.2"]
      },
      "Define performance metrics": {
        "content": "Establish clear and measurable performance metrics for the AI system, aligned with its intended purpose and key requirements.",
        "ref": ["Article 15.2", "Article 15.3"]
      },
      "Conduct validation and testing": {
        "content": "Perform comprehensive validation and testing of the AI system to ensure it meets specified performance metrics and operates as intended.",
        "ref": ["Article 9.6", "Article 9.8"]
      },
      "Document predetermined changes": {
        "content": "Identify and document any predetermined changes or adaptations that the AI system may undergo during its lifecycle, including their potential impacts.",
        "ref": ["Article 13.3.c", "Annex IV.2.f"]
      },
      "Provide log interpretation mechanisms": {
        "content": "Develop and provide mechanisms or tools to interpret the automatically generated logs, enabling effective analysis and understanding of the AI system's behavior.",
        "ref": ["Article 12.2.c", "Article 13.3.f"]
      },
      "Communicate system capabilities": {
        "content": "Clearly communicate the AI system's capabilities, limitations, and expected performance to users and stakeholders, ensuring realistic expectations.",
        "ref": ["Article 13.3.b"]
      }
    },
    "Human Oversight": {
      "Provide human-machine interface tools": {
        "content": "Develop and implement effective human-machine interface tools that enable human operators to interact with and oversee the AI system.",
        "ref": ["Article 14.1", "Article 14.4.a"]
      },
      "Enable understanding of system capabilities": {
        "content": "Provide information and training to human operators to ensure they understand the AI system's capabilities, limitations, and potential risks.",
        "ref": ["Article 14.4.a", "Article 14.4.b"]
      },
      "Ensure transparent operation": {
        "content": "Design the AI system to operate transparently, allowing human operators to interpret and understand its decisions and actions.",
        "ref": ["Article 13.1"]
      },
      "Implement measures against automation bias": {
        "content": "Develop and implement measures to prevent or mitigate automation bias, ensuring that human operators maintain appropriate levels of scrutiny and decision-making authority.",
        "ref": ["Article 14.4.b"]
      },
      "Allow for human intervention": {
        "content": "Incorporate mechanisms that allow for timely human intervention in the AI system's operation when necessary, including the ability to override system decisions.",
        "ref": ["Article 14.4.d", "Article 14.4.e"]
      },
      "Implement 'stop' function": {
        "content": "Implement a clearly identifiable 'stop' function that allows human operators to safely interrupt the AI system's operation in case of emergencies or critical issues.",
        "ref": ["Article 14.4.e"]
      }
    }
  }